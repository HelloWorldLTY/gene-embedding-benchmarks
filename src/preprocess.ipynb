{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import mygene \n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import gseapy as gp\n",
    "import obonet\n",
    "import networkx as nx\n",
    "import random\n",
    "import math\n",
    "import time\n",
    "\n",
    "pd.set_option('display.max_columns', 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "ppi_data = pd.read_csv(\"/network/consensus.dat\", sep=\"\\t\", header=None, names=[\"Gene1\", \"Gene2\"])\n",
    "adj_genes = pd.concat([ppi_data[\"Gene1\"], ppi_data[\"Gene2\"]]).unique()\n",
    "adj_genes = sorted(adj_genes)\n",
    "adj_matrix = np.zeros((len(adj_genes), len(adj_genes)), dtype=int)\n",
    "\n",
    "gene_to_index_adj = {gene: idx for idx, gene in enumerate(adj_genes)}\n",
    "\n",
    "for _, row in ppi_data.iterrows():\n",
    "    i, j = gene_to_index_adj[row[\"Gene1\"]], gene_to_index_adj[row[\"Gene2\"]]\n",
    "    adj_matrix[i, j] = 1  \n",
    "    adj_matrix[j, i] = 1  \n",
    "    \n",
    "adj_df = pd.DataFrame(adj_matrix, index=adj_genes, columns=adj_genes)\n",
    "adj_df.index = adj_df.index.astype(str)\n",
    "adj_df.columns = adj_df.columns.astype(str)\n",
    "\n",
    "adj_df.to_csv(\n",
    "    \"/PPI-RAW_UNIPROT_HUMAN/PPI-RAW_UNIPROT_HUMANemb.csv\", \n",
    "    header=False, \n",
    "    index=False\n",
    ")\n",
    "\n",
    "with open(\"nonmod/PPI-RAW_UNIPROT_HUMAN/PPI-RAW_UNIPROT_HUMANgenelist.txt\", \"w\") as f:\n",
    "    f.write(\"\\n\".join(adj_df.index))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "mg = mygene.MyGeneInfo()\n",
    "\n",
    "processed_dfs = {}\n",
    "entrez_sets = []\n",
    "file_names = \"path to initial embedding files\"\n",
    "\n",
    "for file in file_names:\n",
    "    if file.endswith('.csv'):\n",
    "        filename = '/andes-benchmark-data/' + file\n",
    "        df = pd.read_csv(filename)\n",
    "        print(f\"Processing {file}...\")\n",
    "        \n",
    "        uniprot_ids = df['Entry'].tolist()\n",
    "        mg_results = mg.querymany(uniprot_ids, scopes='uniprot', fields='entrezgene', species='human')\n",
    "        mg_df = pd.DataFrame(mg_results)\n",
    "        \n",
    "        df_with_entrez = df.merge(mg_df[['query', 'entrezgene']], left_on='Entry', right_on='query')\n",
    "        \n",
    "        df_with_entrez.dropna(subset=['entrezgene'], inplace=True)\n",
    "        df_with_entrez.drop(columns=['query', 'Entry'], inplace=True)\n",
    "        df_with_entrez.reset_index(inplace=True)\n",
    "        df_grouped = df_with_entrez.groupby('entrezgene', sort=False).agg({\n",
    "            'index': 'min',\n",
    "            **{col: 'mean' for col in df_with_entrez.columns if col not in ['entrezgene', 'index']}\n",
    "        }).reset_index()\n",
    "        df_grouped.sort_values('index', inplace=True)\n",
    "        df_grouped.drop(columns=['index'], inplace=True)\n",
    "        print(df_grouped.shape)\n",
    "        \n",
    "        processed_dfs[file] = df_grouped\n",
    "        entrez_set = set(df_grouped['entrezgene'])\n",
    "        print(\"initial size: \" + str(len(entrez_set)))\n",
    "        entrez_sets.append(entrez_set)\n",
    "        \n",
    "    else:\n",
    "        print(f\"{file} not csv...\")\n",
    "\n",
    "print(\" \")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "base_dir = '/andes-benchmark-data/nonmod/'\n",
    "os.makedirs(base_dir, exist_ok=True)\n",
    "print(\"nomod\")\n",
    "\n",
    "for file, df in processed_dfs.items():\n",
    "    print(file)\n",
    "    filename = os.path.splitext(os.path.basename(file))[0]\n",
    "    #print(filename)\n",
    "\n",
    "    folder_path = os.path.join(base_dir, filename)\n",
    "    os.makedirs(folder_path, exist_ok=True)\n",
    "\n",
    "    gene_id_list = df['entrezgene'].tolist()\n",
    "    print(len(gene_id_list))\n",
    "    gene_list_file = os.path.join(folder_path, filename + 'genelist.txt')\n",
    "    with open(gene_list_file, 'w') as f:\n",
    "        for gene_id in gene_id_list:\n",
    "            f.write(f\"{gene_id}\\n\")\n",
    "    df_no_entrez = df.drop(columns=['entrezgene'])\n",
    "    \n",
    "    emb_file = os.path.join(folder_path, filename + 'emb.csv')\n",
    "    df_no_entrez.to_csv(emb_file, header=None, index=False)\n",
    "    \n",
    "    print(f\"Saved gene list and embedding files for {filename} in {folder_path}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/nonmod/'\n",
    "subfolders = [f.path for f in os.scandir(folder_path) if f.is_dir()]\n",
    "#subfolders = subfolders[:2]\n",
    "\n",
    "gene_lists = {}\n",
    "embeddings = {}\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    print(f\"Processing subfolder: {subfolder}\")\n",
    "    \n",
    "    gene_txt_files = glob.glob(os.path.join(subfolder, '*.txt'))\n",
    "    if not gene_txt_files:\n",
    "        print(f\"No txt file found in {subfolder}\")\n",
    "        continue\n",
    "    gene_file = gene_txt_files[0]\n",
    "    with open(gene_file, 'r') as f:\n",
    "        genes = [line.strip() for line in f]\n",
    "    gene_lists[subfolder] = genes\n",
    "\n",
    "    csv_files = glob.glob(os.path.join(subfolder, '*.csv'))\n",
    "    if not csv_files:\n",
    "        print(f\"No csv file found in {subfolder}\")\n",
    "        continue\n",
    "    csv_file = csv_files[0]\n",
    "    embedding = pd.read_csv(csv_file, header=None)\n",
    "    \n",
    "    embedding.index = genes\n",
    "    \n",
    "    embeddings[subfolder] = embedding\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "all_gene_sets = [set(gene_lists[sf]) for sf in gene_lists]\n",
    "common_genes = set.intersection(*all_gene_sets)\n",
    "print(f\"Number of common genes across all sets: {len(common_genes)}\")\n",
    "\n",
    "common_genes_ordered = sorted(common_genes)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "output_root = '/mod'\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    if subfolder not in embeddings or subfolder not in gene_lists:\n",
    "        continue\n",
    "    \n",
    "    emb = embeddings[subfolder]\n",
    "    \n",
    "    emb_filtered = emb.loc[common_genes_ordered]\n",
    "    \n",
    "    genes_filtered = common_genes_ordered\n",
    "    \n",
    "    subfolder_name = os.path.basename(subfolder) \n",
    "    output_subfolder = os.path.join(output_root, subfolder_name)\n",
    "    os.makedirs(output_subfolder, exist_ok=True)\n",
    "    \n",
    "    csv_output_path = os.path.join(output_subfolder, f\"{subfolder_name}emb.csv\")\n",
    "    emb_filtered.to_csv(csv_output_path, header=False, index=False)\n",
    "    \n",
    "    txt_output_path = os.path.join(output_subfolder, f\"{subfolder_name}genelist.txt\")\n",
    "    with open(txt_output_path, 'w') as f:\n",
    "        for gene in genes_filtered:\n",
    "            f.write(gene + \"\\n\")\n",
    "    \n",
    "    print(f\"Saved filtered embedding and gene list for {subfolder_name} to {output_subfolder}\")\n",
    "\n",
    "print(\"All filtered embeddings and gene lists saved.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
