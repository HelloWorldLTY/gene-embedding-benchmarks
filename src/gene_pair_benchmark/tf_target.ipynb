{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "f8c9112b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from collections import defaultdict, Counter\n",
    "import os\n",
    "import glob\n",
    "from sklearn.model_selection import train_test_split, KFold\n",
    "from sklearn.metrics import roc_auc_score, average_precision_score, precision_score\n",
    "from xgboost import XGBClassifier\n",
    "from sklearn.svm import SVC\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import time\n",
    "import pickle\n",
    "\n",
    "\n",
    "pd.set_option('display.max_columns', 50) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c92dc228",
   "metadata": {},
   "outputs": [],
   "source": [
    "folder_path = '/andes-benchmark-data/mod/' # embedings who only have genes that are interesected with all the other embedings\n",
    "\n",
    "subfolders = [f.path for f in os.scandir(folder_path) if f.is_dir()]\n",
    "#subfolders = subfolders[:2]  \n",
    "\n",
    "# dict of embeddings and gene list \n",
    "embeddings = {}\n",
    "gene_lists = {}\n",
    "\n",
    "for subfolder in subfolders:\n",
    "    print(f\"Processing subfolder: {subfolder}\")\n",
    "    gene_txt_files = glob.glob(os.path.join(subfolder, '*.txt'))\n",
    "    if not gene_txt_files:\n",
    "        print(f\"No txt file found in {subfolder}\")\n",
    "        continue\n",
    "    gene_file = gene_txt_files[0]\n",
    "    with open(gene_file, 'r') as f:\n",
    "        genes = [line.strip() for line in f]\n",
    "    gene_lists[subfolder] = genes\n",
    "\n",
    "    csv_files = glob.glob(os.path.join(subfolder, '*.csv'))\n",
    "    if not csv_files:\n",
    "        print(f\"No csv file found in {subfolder}\")\n",
    "        continue\n",
    "    csv_file = csv_files[0]\n",
    "    embedding = pd.read_csv(csv_file, header=None)\n",
    "    embeddings[subfolder] = embedding"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "id": "7d8dac67",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/tf_target.txt', sep='\\t')\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "id": "c00cd165",
   "metadata": {},
   "outputs": [],
   "source": [
    "reference_subfolder = list(gene_lists.keys())[0]\n",
    "reference_genes = gene_lists[reference_subfolder] # get an order of genes that the other embeddings will now follow\n",
    "reference_node2index = {x: i for i, x in enumerate(reference_genes)}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "ced7eb54",
   "metadata": {},
   "outputs": [],
   "source": [
    "# reorder all the embedings to have the same order/index\n",
    "for subfolder in gene_lists:\n",
    "    assert set(gene_lists[subfolder]) == set(reference_genes), \"All embeddings must have the same gene set.\"\n",
    "    \n",
    "    current_genes = gene_lists[subfolder]\n",
    "    gene_to_idx = {g: i for i, g in enumerate(current_genes)}\n",
    "    \n",
    "    emb = embeddings[subfolder]\n",
    "    # calculates the order of indices to match\n",
    "    reorder_indices = [gene_to_idx[g] for g in reference_genes]\n",
    "    # reorder the embedings \n",
    "    embeddings[subfolder] = emb.iloc[reorder_indices].reset_index(drop=True)\n",
    "    embeddings[subfolder] = embeddings[subfolder]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "id": "86394be9",
   "metadata": {},
   "outputs": [],
   "source": [
    "for subfolder in embeddings:\n",
    "    embeddings[subfolder] = embeddings[subfolder].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "id": "bea20b51",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "116\n"
     ]
    }
   ],
   "source": [
    "tf_target_counts = data.groupby(\"TF\").size()\n",
    "filtered_tfs = tf_target_counts[(tf_target_counts > 500) & (tf_target_counts < 1000)].index\n",
    "print(len(filtered_tfs))\n",
    "selected_data = data[data[\"TF\"].isin(filtered_tfs)]\n",
    "positive_pairs = []\n",
    "for i in range(selected_data.shape[0]):\n",
    "    a = str(selected_data.iloc[i]['TF'])\n",
    "    b = str(selected_data.iloc[i]['Target'])\n",
    "    positive_pairs.append((min(a, b), max(a, b)))\n",
    "positive_pairs = set(positive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "706febb7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "41445\n"
     ]
    }
   ],
   "source": [
    "positive_pairs = {pair for pair in positive_pairs if pair[0] in reference_node2index and pair[1] in reference_node2index}\n",
    "print(len(positive_pairs))\n",
    "used_nodes = list(set([x for x, y in positive_pairs]).union(set([y for x, y in positive_pairs])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "2636f947-b00c-4b36-8332-88d6a6133be0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "5000\n"
     ]
    }
   ],
   "source": [
    "positive_pairs_all = {pair for pair in positive_pairs if pair[0] in reference_node2index and pair[1] in reference_node2index}\n",
    "positive_pairs = random.sample(positive_pairs_all, 5000)\n",
    "print(len(positive_pairs))\n",
    "used_nodes = list(set([x for x, y in positive_pairs]).union(set([y for x, y in positive_pairs])))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "0355d7a3",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "holdout_fraction = 0.2\n",
    "holdout_size = int(len(used_nodes) * holdout_fraction)\n",
    "\n",
    "random.shuffle(used_nodes)\n",
    "\n",
    "holdout_nodes = used_nodes[:holdout_size]\n",
    "cv_nodes = used_nodes[holdout_size:]\n",
    "\n",
    "num_folds = 3\n",
    "split_size = len(cv_nodes) // num_folds\n",
    "splits = [cv_nodes[:split_size], \n",
    "          cv_nodes[split_size:2*split_size], \n",
    "          cv_nodes[2*split_size:]]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "a351bfe6",
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_data(pairs, emb, mapping):\n",
    "    mapped_pairs = [(mapping[x], mapping[y]) for x, y in pairs]\n",
    "    data = [emb[x] + emb[y] for x, y in mapped_pairs]\n",
    "    return data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "9027239b",
   "metadata": {},
   "outputs": [],
   "source": [
    "random.seed(42)\n",
    "\n",
    "# create the data for models to run on/test on \n",
    "fold_splits = {}\n",
    "for i in range(num_folds):\n",
    "    test_nodes = splits[i]\n",
    "    train_nodes = []\n",
    "    for j in range(num_folds):\n",
    "        if j != i:\n",
    "            train_nodes += splits[j]\n",
    "\n",
    "    train_positive_pairs = [(x, y) for x, y in positive_pairs if x in train_nodes and y in train_nodes]\n",
    "    test_positive_pairs = [(x, y) for x, y in positive_pairs if x in test_nodes and y in test_nodes]\n",
    "\n",
    "    train_all_pairs = [(x, y) for x in train_nodes for y in train_nodes if x < y]\n",
    "    test_all_pairs = [(x, y) for x in test_nodes for y in test_nodes if x < y]\n",
    "\n",
    "    train_negative_pairs = list(set(train_all_pairs) - set(positive_pairs_all))\n",
    "    test_negative_pairs = list(set(test_all_pairs) - set(positive_pairs_all))\n",
    "\n",
    "    random.shuffle(train_negative_pairs)\n",
    "    random.shuffle(test_negative_pairs)\n",
    "    train_negative_pairs = train_negative_pairs[:len(train_positive_pairs)*10]\n",
    "    test_negative_pairs = test_negative_pairs[:len(test_positive_pairs)*10]\n",
    "\n",
    "    fold_splits[i] = {\n",
    "        \"train_pairs\": train_positive_pairs + train_negative_pairs,\n",
    "        \"test_pairs\": test_positive_pairs + test_negative_pairs,\n",
    "        \"train_labels\": [1]*len(train_positive_pairs) + [0]*len(train_negative_pairs),\n",
    "        \"test_labels\": [1]*len(test_positive_pairs) + [0]*len(test_negative_pairs)\n",
    "    }\n",
    "\n",
    "holdout_positive_pairs = [(x, y) for x, y in positive_pairs if x in holdout_nodes and y in holdout_nodes]\n",
    "holdout_all_pairs = [(x, y) for x in holdout_nodes for y in holdout_nodes if x < y]\n",
    "holdout_negative_pairs = list(set(holdout_all_pairs) - set(positive_pairs_all))\n",
    "random.shuffle(holdout_negative_pairs)\n",
    "holdout_negative_pairs = holdout_negative_pairs[:len(holdout_positive_pairs)*10]\n",
    "\n",
    "holdout_pairs = holdout_positive_pairs + holdout_negative_pairs\n",
    "holdout_labels = [1]*len(holdout_positive_pairs) + [0]*len(holdout_negative_pairs)\n",
    "\n",
    "\n",
    "final_train_nodes = cv_nodes\n",
    "final_train_positive_pairs = [(x,y) for x,y in positive_pairs if x in final_train_nodes and y in final_train_nodes]\n",
    "final_train_all_pairs = [(x, y) for x in final_train_nodes for y in final_train_nodes if x < y]\n",
    "final_train_negative_pairs = list(set(final_train_all_pairs) - set(positive_pairs_all))\n",
    "random.shuffle(final_train_negative_pairs)\n",
    "final_train_negative_pairs = final_train_negative_pairs[:len(final_train_positive_pairs)*10]\n",
    "\n",
    "final_train_pairs = final_train_positive_pairs + final_train_negative_pairs\n",
    "final_train_labels = [1]*len(final_train_positive_pairs) + [0]*len(final_train_negative_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "id": "17842db5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total positive pairs: 5000\n",
      "Holdout positive pairs: 225\n",
      "CV positive pairs: 3097\n",
      "Holdout nodes: 762\n",
      "CV nodes: 3052\n"
     ]
    }
   ],
   "source": [
    "print(f\"Total positive pairs: {len(positive_pairs)}\")\n",
    "print(f\"Holdout positive pairs: {len(holdout_positive_pairs)}\")\n",
    "cv_positive_pairs = [(x, y) for x, y in positive_pairs if x in cv_nodes and y in cv_nodes]\n",
    "print(f\"CV positive pairs: {len(cv_positive_pairs)}\")\n",
    "print(f\"Holdout nodes: {len(holdout_nodes)}\")\n",
    "print(f\"CV nodes: {len(cv_nodes)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "71ba40a6-8eae-48a3-89bf-bf2faa124504",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['tf_fold_splits_pairs.pkl',\n",
       " 'tf_fold_nodes.pkl',\n",
       " 'tf_holdout_pairs.pkl',\n",
       " 'tf_holdout_labels.pkl',\n",
       " 'tf_holdout_nodes.pkl']"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "file_names = [\"tf_fold_splits_pairs.pkl\", \"tf_fold_nodes.pkl\", \"tf_holdout_pairs.pkl\", \"tf_holdout_labels.pkl\", \"tf_holdout_nodes.pkl\"]\n",
    "data_dicts = [fold_splits, splits, holdout_pairs,  holdout_labels, holdout_nodes]\n",
    "\n",
    "for file_name, data_dict in zip(file_names, data_dicts):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n",
    "file_names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b84b064-0fa9-40c6-8999-7a652c5b93f5",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38eb4841",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_results_records = []\n",
    "holdout_results_records = []\n",
    "\n",
    "def log_print(msg, log_file=\"tf_output_log.txt\"):\n",
    "    print(msg)\n",
    "    with open(log_file, \"a\") as f:\n",
    "        f.write(msg + \"\\n\")\n",
    "\n",
    "def precision_at_k(y_true, y_scores, k=10):\n",
    "    \"\"\"Calculate Precision at K.\"\"\"\n",
    "    if len(y_scores) > k:\n",
    "        top_k_indices = np.argsort(y_scores)[-k:][::-1]\n",
    "    else:\n",
    "        top_k_indices = np.argsort(y_scores)[::-1]\n",
    "    top_k_true = np.array(y_true)[top_k_indices]\n",
    "    return np.mean(top_k_true)\n",
    "\n",
    "C_values = [0.1, 1, 10, 100, 1000]\n",
    "\n",
    "for subfolder in embeddings:\n",
    "    emb = embeddings[subfolder]\n",
    "    log_print(f\"Evaluating embedding from subfolder: {subfolder}\")\n",
    "\n",
    "    c_performance = []\n",
    "\n",
    "    for C in C_values:\n",
    "        fold_results = []\n",
    "        fold_times = [] \n",
    "        log_print(f\"Testing C={C}\")\n",
    "        for i in range(num_folds):\n",
    "            fold_start_time = time.time()  \n",
    "            \n",
    "            test_nodes = splits[i]\n",
    "            train_nodes = []\n",
    "            for j in range(num_folds):\n",
    "                if j != i:\n",
    "                    train_nodes += splits[j]\n",
    "\n",
    "            fold_data = fold_splits[i]\n",
    "            train_pairs = fold_data[\"train_pairs\"]\n",
    "            test_pairs = fold_data[\"test_pairs\"]\n",
    "            train_label = fold_data[\"train_labels\"]\n",
    "            test_label = fold_data[\"test_labels\"]\n",
    "\n",
    "            train_data = get_data(train_pairs, emb, reference_node2index)\n",
    "            test_data = get_data(test_pairs, emb, reference_node2index)\n",
    "\n",
    "            clf = SVC(class_weight='balanced', C=C)\n",
    "            clf.fit(train_data, train_label)\n",
    "            probabilities = clf.decision_function(test_data)\n",
    "\n",
    "            auc = roc_auc_score(test_label, probabilities)\n",
    "            auprc = average_precision_score(test_label, probabilities)\n",
    "            pr10 = precision_at_k(test_label, probabilities, k=10)\n",
    "\n",
    "            fold_end_time = time.time()  \n",
    "            fold_duration = fold_end_time - fold_start_time  \n",
    "            fold_times.append(fold_duration)\n",
    "\n",
    "            log_print(f\"Fold {i + 1}: AUC: {auc:.4f}, AUPRC: {auprc:.4f}, PR@10: {pr10:.4f}, Time: {fold_duration:.2f}s\")\n",
    "            fold_results.append((auc, auprc, pr10))\n",
    "\n",
    "        avg_auc = np.mean([r[0] for r in fold_results])\n",
    "        avg_auprc = np.mean([r[1] for r in fold_results])\n",
    "        avg_pr10 = np.mean([r[2] for r in fold_results])\n",
    "        avg_fold_time = np.mean(fold_times) \n",
    "        log_print(f\"Cross-val average for C={C}: AUC={avg_auc:.4f}, AUPRC={avg_auprc:.4f}, PR@10={avg_pr10:.4f}, Avg Time/Fold: {avg_fold_time:.2f}s\")\n",
    "\n",
    "        c_performance.append({\n",
    "            'C': C,\n",
    "            'AUC': avg_auc,\n",
    "            'AUPRC': avg_auprc,\n",
    "            'PR@10': avg_pr10,\n",
    "            'avg_fold_time': avg_fold_time  \n",
    "        })\n",
    "\n",
    "    best_C_entry = max(c_performance, key=lambda x: x['AUC'])\n",
    "    best_C = best_C_entry['C']\n",
    "    best_avg_auc = best_C_entry['AUC']\n",
    "    best_avg_auprc = best_C_entry['AUPRC']\n",
    "    best_avg_pr10 = best_C_entry['PR@10']\n",
    "    best_avg_fold_time = best_C_entry['avg_fold_time']\n",
    "\n",
    "    log_print(f\"Best C for {subfolder}: C={best_C} with AUC={best_avg_auc:.4f}, AUPRC={best_avg_auprc:.4f}, PR@10={best_avg_pr10:.4f}, Avg Time/Fold: {best_avg_fold_time:.2f}s\")\n",
    "\n",
    "    fold_results_records.append({\n",
    "        'subfolder': subfolder,\n",
    "        'C': best_C,\n",
    "        'AUC': best_avg_auc,\n",
    "        'AUPRC': best_avg_auprc,\n",
    "        'PR@10': best_avg_pr10,\n",
    "        'avg_fold_time': best_avg_fold_time\n",
    "    })\n",
    "\n",
    "    holdout_start_time = time.time()\n",
    "\n",
    "    final_train_data = get_data(final_train_pairs, emb, reference_node2index)\n",
    "    final_clf = SVC(class_weight='balanced', C=best_C)\n",
    "    final_clf.fit(final_train_data, final_train_labels)\n",
    "\n",
    "    holdout_data = get_data(holdout_pairs, emb, reference_node2index)\n",
    "    holdout_prob = final_clf.decision_function(holdout_data)\n",
    "\n",
    "    holdout_auc = roc_auc_score(holdout_labels, holdout_prob)\n",
    "    holdout_auprc = average_precision_score(holdout_labels, holdout_prob)\n",
    "    holdout_pr10 = precision_at_k(holdout_labels, holdout_prob, k=10)\n",
    "\n",
    "    holdout_end_time = time.time()\n",
    "    holdout_duration = holdout_end_time - holdout_start_time  \n",
    "\n",
    "    log_print(f\"Holdout performance for {subfolder} with best C={best_C}:\")\n",
    "    log_print(f\"Holdout AUC: {holdout_auc:.4f}\")\n",
    "    log_print(f\"Holdout AUPRC: {holdout_auprc:.4f}\")\n",
    "    log_print(f\"Holdout PR@10: {holdout_pr10:.4f}\")\n",
    "    log_print(f\"Holdout Duration: {holdout_duration:.2f}s\")\n",
    "\n",
    "    holdout_results_records.append({\n",
    "        'subfolder': subfolder,\n",
    "        'C': best_C,\n",
    "        'AUC': holdout_auc,\n",
    "        'AUPRC': holdout_auprc,\n",
    "        'PR@10': holdout_pr10,\n",
    "        'holdout_time': holdout_duration\n",
    "    })"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3ec5911",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_results_df = pd.DataFrame(fold_results_records).set_index('subfolder')\n",
    "holdout_results_df = pd.DataFrame(holdout_results_records).set_index('subfolder')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fbb451",
   "metadata": {},
   "outputs": [],
   "source": [
    "fold_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "761266e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_fold_results_df = fold_results_df.sort_values(by='AUPRC', ascending=False)\n",
    "sorted_fold_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "94c4c88b",
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b93bda98",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_holdout_results_df = holdout_results_df.sort_values(by='AUPRC', ascending=False)\n",
    "sorted_holdout_results_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcea909",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_fold_results_df['dim'] = sorted_fold_results_df.index.map(lambda sf: embeddings[sf].shape[1])\n",
    "sorted_holdout_results_df['dim'] = sorted_holdout_results_df.index.map(lambda sf: embeddings[sf].shape[1])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "55a2c6b6",
   "metadata": {},
   "outputs": [],
   "source": [
    "plt.figure(figsize=(15, 5))\n",
    "\n",
    "sns.scatterplot(x='dim', y='AUC', data=sorted_fold_results_df.reset_index(), label='Fold AUC', s=50, color='blue', marker='o')\n",
    "sns.lineplot(x='dim', y='AUC', data=sorted_fold_results_df.reset_index(), label=None, color='blue', linestyle='--')\n",
    "\n",
    "sns.scatterplot(x='dim', y='AUC', data=sorted_holdout_results_df.reset_index(), label='Holdout AUC', s=50, color='green', marker='s')\n",
    "sns.lineplot(x='dim', y='AUC', data=sorted_holdout_results_df.reset_index(), label=None, color='green', linestyle='--')\n",
    "\n",
    "sns.scatterplot(x='dim', y='AUPRC', data=sorted_fold_results_df.reset_index(), label='Fold AUPRC', s=50, color='orange', marker='^')\n",
    "sns.lineplot(x='dim', y='AUPRC', data=sorted_fold_results_df.reset_index(), label=None, color='orange', linestyle='--')\n",
    "\n",
    "sns.scatterplot(x='dim', y='AUPRC', data=sorted_holdout_results_df.reset_index(), label='Holdout AUPRC', s=50, color='red', marker='v')\n",
    "sns.lineplot(x='dim', y='AUPRC', data=sorted_holdout_results_df.reset_index(), label=None, color='red', linestyle='--')\n",
    "\n",
    "plt.title('Performance Metrics vs Embedding Dimension')\n",
    "plt.xlabel('Embedding Dimension')\n",
    "plt.ylabel('Performance Metric')\n",
    "plt.grid(True)\n",
    "plt.legend(loc='best', title='Metrics', fontsize=10)\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67d295c5",
   "metadata": {},
   "outputs": [],
   "source": [
    "combined_df = sorted_fold_results_df[['AUC','AUPRC','PR@10']].copy()\n",
    "combined_df.rename(columns={'AUC': 'Avg 3 Fold AUC', 'AUPRC': 'Avg 3 Fold AUPRC', 'PR@10': 'Avg 3 Fold PR@10'}, inplace=True)\n",
    "\n",
    "combined_df['Holdout AUC'] = sorted_holdout_results_df['AUC']\n",
    "combined_df['Holdout AUPRC'] = sorted_holdout_results_df['AUPRC']\n",
    "combined_df['Holdout PR@10'] = sorted_holdout_results_df['PR@10']\n",
    "combined_df['dim'] = sorted_holdout_results_df['dim']\n",
    "\n",
    "\n",
    "combined_df.index = combined_df.apply(lambda row: f\"{row.name}:{int(row['dim'])}\", axis=1)\n",
    "combined_df = combined_df.drop(columns=['dim'])\n",
    "\n",
    "g = sns.clustermap(combined_df,\n",
    "                   metric='euclidean',\n",
    "                   method='average',\n",
    "                   cmap='viridis',\n",
    "                   annot=True,\n",
    "                   fmt=\".3f\",\n",
    "                   figsize=(10,10))\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8d859923",
   "metadata": {},
   "outputs": [],
   "source": [
    "sorted_combined_df = combined_df.sort_values(by='Holdout AUC', ascending=False)\n",
    "\n",
    "plt.figure(figsize=(10, 7))\n",
    "\n",
    "\n",
    "g = sns.heatmap(sorted_combined_df,\n",
    "                cmap='viridis',\n",
    "                annot=True,\n",
    "                cbar=True)\n",
    "\n",
    "plt.xlabel(\"Metrics\")\n",
    "plt.ylabel(\"Embedding:Dimension\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "9b1576b5-6115-4d1d-84db-242f923e1336",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "DataFrames saved successfully to tf_fold_results_df.csv and tf_holdout_results_df.csv.\n"
     ]
    }
   ],
   "source": [
    "fold_results_file = \"tf_fold_results_df.csv\"\n",
    "holdout_results_file = \"tf_holdout_results_df.csv\"\n",
    "\n",
    "try:\n",
    "    sorted_fold_results_df.to_csv(fold_results_file, index=True)\n",
    "    sorted_holdout_results_df.to_csv(holdout_results_file, index=True)\n",
    "    print(f\"DataFrames saved successfully to {fold_results_file} and {holdout_results_file}.\")\n",
    "except Exception as e:\n",
    "    print(f\"An error occurred: {e}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "fec614b2-a7da-4f45-be53-0c15e65c75c1",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
