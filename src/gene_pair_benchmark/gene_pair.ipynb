{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import helper \n",
    "import pickle \n",
    "from matplotlib.lines import Line2D\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import statsmodels.api as sm\n",
    "import statsmodels.formula.api as smf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "embeddings, reference_node2index = helper.load_embeddings()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/biogrid/BIOGRID-ORGANISM-Homo_sapiens-4.4.240.tab3.txt', sep='\\t')\n",
    "\n",
    "data = data[(data['Organism ID Interactor A'] == 9606) & \n",
    "            (data['Organism ID Interactor B'] == 9606)]\n",
    "data = data[data['Experimental System Type'] == 'genetic']\n",
    "\n",
    "selected_data = data[data['Experimental System'] == 'Synthetic Lethality']\n",
    "positive_pairs = []\n",
    "for i in range(selected_data.shape[0]):\n",
    "    a = str(selected_data.iloc[i]['Entrez Gene Interactor A'])\n",
    "    b = str(selected_data.iloc[i]['Entrez Gene Interactor B'])\n",
    "    positive_pairs.append((min(a, b), max(a, b)))\n",
    "positive_pairs = set(positive_pairs)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs = {pair for pair in positive_pairs if pair[0] in reference_node2index and pair[1] in reference_node2index}\n",
    "print(len(positive_pairs))\n",
    "used_nodes = list(set([x for x, y in positive_pairs]).union(set([y for x, y in positive_pairs])))\n",
    "\n",
    "holdout_nodes, splits, cv_nodes = helper.fold_split(used_nodes)\n",
    "fold_splits, holdout_pairs, holdout_labels, final_train_pairs, final_train_labels = helper.setup_data(positive_pairs, splits, holdout_nodes, cv_nodes)\n",
    "\n",
    "# save holdout and fold splits \n",
    "file_names = [\"sl_fold_splits_pairs.pkl\", \"sl_fold_nodes.pkl\", \"sl_holdout_pairs.pkl\", \"sl_holdout_labels.pkl\", \"sl_holdout_nodes.pkl\"]\n",
    "data_dicts = [fold_splits, splits, holdout_pairs,  holdout_labels, holdout_nodes]\n",
    "\n",
    "for file_name, data_dict in zip(file_names, data_dicts):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n",
    "sl_fold_results_df, sl_holdout_results_df = helper.run_SVM(embeddings, reference_node2index, splits, fold_splits, holdout_pairs, holdout_labels, final_train_pairs, final_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/biogrid/BIOGRID-ORGANISM-Homo_sapiens-4.4.240.tab3.txt', sep='\\t')\n",
    "\n",
    "data = data[(data['Organism ID Interactor A'] == 9606) & \n",
    "            (data['Organism ID Interactor B'] == 9606)]\n",
    "data = data[data['Experimental System Type'] == 'genetic']\n",
    "\n",
    "selected_data = data[data['Experimental System'] == 'Negative Genetic']\n",
    "positive_pairs = []\n",
    "for i in range(selected_data.shape[0]):\n",
    "    a = str(selected_data.iloc[i]['Entrez Gene Interactor A'])\n",
    "    b = str(selected_data.iloc[i]['Entrez Gene Interactor B'])\n",
    "    positive_pairs.append((min(a, b), max(a, b)))\n",
    "positive_pairs = set(positive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs = {pair for pair in positive_pairs if pair[0] in reference_node2index and pair[1] in reference_node2index}\n",
    "print(len(positive_pairs))\n",
    "used_nodes = list(set([x for x, y in positive_pairs]).union(set([y for x, y in positive_pairs])))\n",
    "\n",
    "holdout_nodes, splits, cv_nodes = helper.fold_split(used_nodes)\n",
    "fold_splits, holdout_pairs, holdout_labels, final_train_pairs, final_train_labels = helper.setup_data(positive_pairs, splits, holdout_nodes, cv_nodes)\n",
    "\n",
    "# save holdout and fold splits \n",
    "file_names = [\"ng_fold_splits_pairs.pkl\", \"ng_fold_nodes.pkl\", \"ng_holdout_pairs.pkl\", \"ng_holdout_labels.pkl\", \"ng_holdout_nodes.pkl\"]\n",
    "data_dicts = [fold_splits, splits, holdout_pairs,  holdout_labels, holdout_nodes]\n",
    "\n",
    "for file_name, data_dict in zip(file_names, data_dicts):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n",
    "ng_fold_results_df, ng_holdout_results_df = helper.run_SVM(embeddings, reference_node2index, splits, fold_splits, holdout_pairs, holdout_labels, final_train_pairs, final_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('/data/tf_target.txt', sep='\\t')\n",
    "\n",
    "tf_target_counts = data.groupby(\"TF\").size()\n",
    "filtered_tfs = tf_target_counts[(tf_target_counts > 500) & (tf_target_counts < 1000)].index\n",
    "print(len(filtered_tfs))\n",
    "selected_data = data[data[\"TF\"].isin(filtered_tfs)]\n",
    "positive_pairs = []\n",
    "for i in range(selected_data.shape[0]):\n",
    "    a = str(selected_data.iloc[i]['TF'])\n",
    "    b = str(selected_data.iloc[i]['Target'])\n",
    "    positive_pairs.append((min(a, b), max(a, b)))\n",
    "positive_pairs = set(positive_pairs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "positive_pairs = {pair for pair in positive_pairs if pair[0] in reference_node2index and pair[1] in reference_node2index}\n",
    "print(len(positive_pairs))\n",
    "used_nodes = list(set([x for x, y in positive_pairs]).union(set([y for x, y in positive_pairs])))\n",
    "\n",
    "holdout_nodes, splits, cv_nodes = helper.fold_split(used_nodes)\n",
    "fold_splits, holdout_pairs, holdout_labels, final_train_pairs, final_train_labels = helper.setup_data(positive_pairs, splits, holdout_nodes, cv_nodes)\n",
    "\n",
    "# save holdout and fold splits \n",
    "file_names = [\"tf_fold_splits_pairs.pkl\", \"tf_fold_nodes.pkl\", \"tf_holdout_pairs.pkl\", \"tf_holdout_labels.pkl\", \"tf_holdout_nodes.pkl\"]\n",
    "data_dicts = [fold_splits, splits, holdout_pairs,  holdout_labels, holdout_nodes]\n",
    "\n",
    "for file_name, data_dict in zip(file_names, data_dicts):\n",
    "    with open(file_name, 'wb') as f:\n",
    "        pickle.dump(data_dict, f)\n",
    "\n",
    "tf_fold_results_df, tf_holdout_results_df = helper.run_SVM(embeddings, reference_node2index, splits, fold_splits, holdout_pairs, holdout_labels, final_train_pairs, final_train_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "meta_df = pd.read_csv('/data/z_benchmark_embed_meta.csv', index_col=0, encoding='utf-8')\n",
    "meta_df.index = meta_df.index.str.replace(r'\\s+', '', regex=True)\n",
    "\n",
    "holdout_df = pd.concat([sl_holdout_results_df, ng_holdout_results_df, tf_holdout_results_df], ignore_index=True)\n",
    "holdout_auc = holdout_df.pivot(index='subfolder', columns='benchmark', values='AUC')\n",
    "holdout_auc = holdout_auc[['ssl', 'ng', 'tf']]\n",
    "holdout_auc['average_auc'] = holdout_auc.mean(axis=1)\n",
    "holdout_auc = holdout_auc.sort_values(by='average_auc', ascending=False)\n",
    "holdout_auc = holdout_auc.drop(columns=['average_auc'])\n",
    "holdout_auc['data'] = meta_df.loc[holdout_auc.index, 'Category'].values\n",
    "holdout_auc['algorithm'] = meta_df.loc[holdout_auc.index, 'Method'].values\n",
    "holdout_auc['Dimensions'] = meta_df.loc[holdout_auc.index, 'Dimensions'].values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_long = holdout_auc.reset_index().melt(\n",
    "    id_vars=['subfolder', 'data', 'algorithm', 'Dimensions'],  \n",
    "    value_vars=['sl', 'ng', 'tf'],  \n",
    "    var_name='Benchmark',  \n",
    "    value_name='AUC'       \n",
    ")\n",
    "\n",
    "benchmark_colors = {'sl': 'maroon', 'ng': 'navy', 'tf': '#173317'}\n",
    "benchmark_markers = {'sl': 'o', 'ng': '>', 'tf': 's'}\n",
    "\n",
    "plt.figure(figsize=(6.5, 8))\n",
    "for benchmark in holdout_long['Benchmark'].unique():\n",
    "    benchmark_data = holdout_long[holdout_long['Benchmark'] == benchmark]\n",
    "    sns.stripplot(\n",
    "        data=benchmark_data,\n",
    "        x='AUC',\n",
    "        y='subfolder',\n",
    "        color=benchmark_colors[benchmark],  \n",
    "        marker=benchmark_markers[benchmark],  \n",
    "        size=8,  \n",
    "        alpha=0.8,  \n",
    "        label=benchmark  \n",
    "    )\n",
    "\n",
    "plt.title(\"\", fontsize=16)\n",
    "plt.xlabel(\"AUC\", fontsize=12)\n",
    "plt.ylabel(\"\", fontsize=12)\n",
    "\n",
    "legend_elements = [\n",
    "    Line2D([0], [0], color='maroon', marker='o', linestyle='', label='sl'),\n",
    "    Line2D([0], [0], color='navy', marker='>', linestyle='', label='ng'),\n",
    "    Line2D([0], [0], color='#173317', marker='s', linestyle='', label='tf')\n",
    "]\n",
    "\n",
    "plt.legend(\n",
    "    handles=legend_elements,\n",
    "    title=\"\",\n",
    "    loc='lower right',  \n",
    "    frameon=True  \n",
    ")\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(\"/results/plots/holdout_genepair_dot_plot.pdf\", format=\"pdf\", bbox_inches=\"tight\")\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "holdout_auc['Dimension_2'] = holdout_auc['Dimensions'].apply(lambda x: x[1])\n",
    "\n",
    "def calculate_anova_with_ratios(dependent_variable, data):\n",
    "    print(f\"\\nANOVA for {dependent_variable}\")\n",
    "    model = smf.ols(f'{dependent_variable} ~ data + algorithm + Dimension_2', data=data).fit()\n",
    "    anova_table = sm.stats.anova_lm(model, typ=2)\n",
    "    \n",
    "    total_sum_sq = anova_table[\"sum_sq\"].sum()\n",
    "    anova_table[\"ratio\"] = anova_table[\"sum_sq\"] / total_sum_sq\n",
    "    \n",
    "    print(anova_table)\n",
    "    return anova_table\n",
    "\n",
    "ssl_anova = calculate_anova_with_ratios(\"sl\", holdout_auc)\n",
    "ng_anova = calculate_anova_with_ratios(\"ng\", holdout_auc)\n",
    "tf_anova = calculate_anova_with_ratios(\"tf\", holdout_auc)"
   ]
  }
 ],
 "metadata": {
  "language_info": {
   "name": "python"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
